{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Wheeler Traffic Rule Violation Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detected Objects\n",
    "- Helmet Detection Project: Two-wheeler/motorcyclist, Helmet, License Plate\n",
    "- Face Detection: Human Face\n",
    "- Two Wheeler Lane Detection: Front-facing motorcycle, Rear-facing motorcycle\n",
    "\n",
    "## Violations\n",
    "- Wrong Lane: Driving away from the camera.\n",
    "- No Helmet: Any rider not wearing a helmet.\n",
    "- Triple riding: More than two riders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Motorcycle Detection:**\n",
    "   - Detects all two-wheelers/motorcycles in a frame.\n",
    "2. **Bounding Box Extraction:**\n",
    "   - For each detected motorcycle, extracts its bounding box.\n",
    "3. **Orientation Check:**\n",
    "   - Determines if the motorcycle is front-facing or rear-facing.\n",
    "   - Flags a \"Wrong Lane Violation\" if the motorcycle is rear-facing.\n",
    "4. **Face and Helmet Detection:**\n",
    "   - Detects faces and helmets within the cropped image.\n",
    "   - Counts the number of faces.\n",
    "   - Reduces the face count if the detected face and helmet areas overlap by more than 60%.\n",
    "5. **No Helmet Violation:**\n",
    "   - Detects helmets again and counts them.\n",
    "   - Flags a \"No Helmet Violation\" if no helmets are detected or if the number of faces is greater than 1.\n",
    "6. **Triple Riding Violation:**\n",
    "   - Sums up the final counts of helmets and faces.\n",
    "   - Flags a \"Triple Riding Violation\" if the sum is greater than 2.\n",
    "7. **License Plate Detection:**\n",
    "   - If any violation is detected, captures the license plate using the [OCR.Space API](https://ocr.space/OCRAPI).\n",
    "8. **Saving Violation Data:**\n",
    "   - Saves the violated motorcycle image along with its license plate image and text.\n",
    "   - Records the list of violations for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from decouple import config\n",
    "from inference_sdk import InferenceHTTPClient, InferenceConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCR_SPACE_API='K83477182488957'\n",
    "ROBOFLOW_API_KEY='BvPPy1sFAKaldwdqJk55'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `ocr_space_file`\n",
    "\n",
    "1. **Function Definition**: The function `ocr_space_file` takes four parameters:\n",
    "   - `filename`: The path to the image file from which text will be extracted.\n",
    "   - `overlay`: A boolean that indicates whether overlay information should be included in the response.\n",
    "   - `api_key`: The API key required for authenticating requests to the OCR.Space API.\n",
    "   - `language`: A string representing the language code for OCR, such as 'eng' for English.\n",
    "\n",
    "2. **Payload Preparation**: A dictionary `payload` is created to hold the parameters required for the API request. This includes the overlay requirement, the API key, the language, and the OCR engine version.\n",
    "\n",
    "3. **File Handling**: The image file specified by `filename` is opened in binary mode (`'rb'`). The file is then sent in a POST request to the OCR.Space API.\n",
    "\n",
    "4. **Response Handling**: The response is decoded and converted from JSON format into a Python dictionary. It checks whether the `ParsedResults` key exists and if it contains results.\n",
    "\n",
    "5. **Text Extraction**: The function retrieves lines of text from the response and concatenates them into a single string representing the license plate number.\n",
    "\n",
    "6. **Text Cleaning**: The extracted text is cleaned using a regular expression to remove any characters that are not alphanumeric.\n",
    "\n",
    "7. **Return Value**: The cleaned license plate number is returned. If no text is found, the function returns `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_space_file(filename, overlay, api_key, language):\n",
    "    payload = {\n",
    "                'isOverlayRequired': overlay,\n",
    "                'apikey': api_key,\n",
    "                'language': language,\n",
    "                'OCREngine': 2,\n",
    "            }\n",
    "    with open(filename, 'rb') as f:\n",
    "        r = requests.post('https://api.ocr.space/parse/image',\n",
    "                        files={filename: f},\n",
    "                        data=payload,\n",
    "                        )\n",
    "    data = json.loads(r.content.decode())\n",
    "\n",
    "    lines = data[\"ParsedResults\"][0][\"TextOverlay\"][\"Lines\"]\n",
    "\n",
    "    lpnum = \"\".join(line[\"LineText\"] for line in lines)\n",
    "    lpnum = re.sub(r'[^a-zA-Z0-9]', '', lpnum)\n",
    "    \n",
    "    return lpnum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `draw_detections`\n",
    "\n",
    "1. **Function Definition**: \n",
    "   - The function `draw_detections` takes in three prediction dictionaries (`p1`, `p2`, `p3`) and an image (`img`) as inputs.\n",
    "   - Each prediction dictionary contains a list of detected objects, each represented as a dictionary with properties for position, size, class, and confidence.\n",
    "\n",
    "2. **Class Color Mapping**:\n",
    "   - A dictionary `class_colors` maps detection classes (like helmets and motorcyclists) to specific colors. This helps visually distinguish different types of objects in the image.\n",
    "\n",
    "3. **Drawing Context**:\n",
    "   - The function creates a drawing context using `ImageDraw.Draw(img)` from the Pillow library, allowing the function to draw shapes and text on the image.\n",
    "\n",
    "4. **Combining Predictions**:\n",
    "   - The predictions from all three input dictionaries are combined into a single list for easier processing.\n",
    "\n",
    "5. **Iterating Through Predictions**:\n",
    "   - The function loops over each prediction to extract its bounding box coordinates (`x`, `y`, `width`, and `height`).\n",
    "   - It calculates the corners of the bounding box (`x1`, `y1`, `x2`, `y2`) based on the center position (`x`, `y`) and dimensions.\n",
    "\n",
    "6. **Label Positioning**:\n",
    "   - Depending on the class of the detected object, the function determines where to draw the label background rectangle (above or below the bounding box) and sets the label position accordingly.\n",
    "\n",
    "7. **Drawing Bounding Boxes**:\n",
    "   - A rectangle is drawn around the detected object using `draw.rectangle`, outlining the bounding box in the color corresponding to the object's class.\n",
    "\n",
    "8. **Labeling**:\n",
    "   - The label text, which includes the class name and confidence score (formatted to two decimal places), is drawn on the image using the `draw.text` method.\n",
    "\n",
    "9. **Return Value**:\n",
    "   - Finally, the modified image, with all detections visualized, is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_detections(p1, p2, p3, img):\n",
    "    class_colors = {\n",
    "        'helmet': 'blue',\n",
    "        'motorcyclist': 'green',\n",
    "        'license_plate': 'red',\n",
    "        'face': 'darkmagenta',\n",
    "        'front': 'darkgoldenrod',\n",
    "        'rear': 'darkorchid'\n",
    "    }\n",
    "    \n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    preds = {'predictions': p1['predictions'] + p2['predictions'] + p3['predictions']}\n",
    "\n",
    "    for prediction in preds['predictions']:\n",
    "        x, y, width, height = (\n",
    "            prediction['x'],\n",
    "            prediction['y'],\n",
    "            prediction['width'],\n",
    "            prediction['height']\n",
    "        )\n",
    "        \n",
    "        x1 = x - width / 2\n",
    "        y1 = y - height / 2\n",
    "        x2 = x + width / 2\n",
    "        y2 = y + height / 2\n",
    "        \n",
    "        class_name = prediction['class']\n",
    "        confidence = prediction['confidence']\n",
    "        \n",
    "        label_color = class_colors.get(class_name, 'black')\n",
    "\n",
    "        if class_name=='motorcyclist':\n",
    "            draw.rectangle([x1, y1, x2, y1+14], fill=label_color)\n",
    "            label_position = (x1 + 5, y1 + 2)\n",
    "        else:\n",
    "            draw.rectangle([x1, y1-14, x2, y1], fill=label_color)\n",
    "            label_position = (x1 + 5, y1-12)\n",
    "            \n",
    "        draw.rectangle([x1, y1, x2, y2], outline=label_color, width=2)\n",
    "\n",
    "        label = f\"{class_name} ({confidence:.2f})\"\n",
    "        draw.text(label_position,label, fill='white')\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roboflow API keys\n",
    "roboflow_api_key = config(\"ROBOFLOW_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<inference_sdk.http.client.InferenceHTTPClient at 0x1514e6bd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_configuration = InferenceConfiguration(confidence_threshold=0.4, iou_threshold=0.4)\n",
    "client1 = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=roboflow_api_key\n",
    ")\n",
    "client1.configure(custom_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<inference_sdk.http.client.InferenceHTTPClient at 0x156428d10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_configuration = InferenceConfiguration(confidence_threshold=0.4, iou_threshold=0.3)\n",
    "client2 = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=roboflow_api_key\n",
    ")\n",
    "client2.configure(custom_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<inference_sdk.http.client.InferenceHTTPClient at 0x157926f50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_configuration = InferenceConfiguration(confidence_threshold=0.1, iou_threshold=0.1)\n",
    "client3 = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=roboflow_api_key\n",
    ")\n",
    "client3.configure(custom_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'image_239_jpg.rf.d30643c4a7f593d85fe0a063af8061f7.jpg'\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get video details\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = cap.get(5)\n",
    "total_frames = int(cap.get(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violate Date folder\n",
    "current_date = datetime.now(timezone.utc).astimezone(timezone(timedelta(hours=5, minutes=30))).strftime(\"%d-%m-%Y\")\n",
    "folder_path = os.path.join(os.getcwd(), f\"Violations/{current_date}\")\n",
    "os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Frame Processing for Violations Detection\n",
    "\n",
    "1. **Frame Extraction**: The code processes every 180th frame of the video to reduce computational load. It reads the video frame using OpenCV and converts it into a format compatible with the Pillow library for further processing.\n",
    "\n",
    "2. **Model Inference**:\n",
    "   - The frame is saved temporarily and analyzed by three different models:\n",
    "     - **Helmet Detection**: Checks for the presence of helmets on the motorcyclist.\n",
    "     - **Face Detection**: Identifies the faces of the motorcyclist and any passengers.\n",
    "     - **Lane Detection**: Determines if the motorcyclist is riding in the correct lane.\n",
    "\n",
    "3. **Violation Detection**:\n",
    "   - After extracting predictions from the models, the code checks for various conditions:\n",
    "     - If the motorcyclist is detected without a helmet.\n",
    "     - If there are faces detected within the bounds of the motorcyclist's area.\n",
    "     - If the motorcyclist is in the wrong lane as indicated by lane detection.\n",
    "     - If the total number of detected individuals exceeds two (indicating triple riding).\n",
    "\n",
    "4. **License Plate Recognition**:\n",
    "   - If any violations are detected, the code looks for a license plate in the frame.\n",
    "   - It crops the detected license plate region and uses an OCR service to extract the license plate number.\n",
    "   - The results are saved along with the images of the motorcyclist and the license plate in a structured folder.\n",
    "\n",
    "5. **File Management**: The code creates directories to organize the output based on the detected violations and cleans up temporary files after processing.\n",
    "\n",
    "### Code Structure\n",
    "- **Image Drawing Function**: The `draw_detections` function visually annotates the detections on the motorcyclistâ€™s image, highlighting the detected classes (helmet, face, etc.) and their confidence scores.\n",
    "- **Detection Logic**: Nested loops handle detection logic, ensuring correct identification and preventing overlap between detected faces and helmets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   0%|          | 0/1 [00:00<?, ?frames/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process every 60th frame\n",
    "for frame_number in tqdm(range(0, total_frames, 180), desc=\"Processing frames\", unit=\"frames\"):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    pil_frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    image_path = \"temp_frame.jpg\"\n",
    "    pil_frame.save(image_path)\n",
    "\n",
    "    r1 = client1.infer(image_path, model_id=\"helmet-detection-project/13\")\n",
    "    pred1 = r1['predictions']\n",
    "\n",
    "    for pr1 in pred1:\n",
    "        helmet_detected = False\n",
    "        face_detected = False\n",
    "        rear_detected = False\n",
    "        more_than_two_detected = False\n",
    "        num_faces_detected = 0\n",
    "        num_helmets_detected = 0\n",
    "\n",
    "        if pr1['class'] == 'motorcyclist':\n",
    "            motorcyclist_x, motorcyclist_y, motorcyclist_width, motorcyclist_height = pr1['x'], pr1['y'], pr1['width'], pr1['height']\n",
    "            \n",
    "            motorcyclist_x1, motorcyclist_y1 = int(motorcyclist_x - motorcyclist_width / 2), int(motorcyclist_y - motorcyclist_height / 2)\n",
    "            motorcyclist_x2, motorcyclist_y2 = int(motorcyclist_x + motorcyclist_width / 2), int(motorcyclist_y + motorcyclist_height / 2)\n",
    "            \n",
    "            motorcyclist_image = pil_frame.crop((motorcyclist_x1, motorcyclist_y1, motorcyclist_x2, motorcyclist_y2))\n",
    "            motorcyclist_image.save(\"temp_motorcyclist_image.jpg\")\n",
    "\n",
    "            # Lane check\n",
    "            r3 = client3.infer(\"temp_motorcyclist_image.jpg\", model_id=\"two-wheeler-lane-detection/3\")\n",
    "            lane = r3\n",
    "\n",
    "            if lane['predictions']:\n",
    "                max_conf = max(lane['predictions'], key=lambda x: x['confidence'])\n",
    "                lane['predictions'] = [max_conf]\n",
    "            \n",
    "            pred3 = lane['predictions']\n",
    "            \n",
    "            for lane_prediction in pred3:\n",
    "                if lane_prediction['class'] == 'rear':\n",
    "                    rear_x, rear_y, rear_width, rear_height = lane_prediction['x'], lane_prediction['y'], lane_prediction['width'], lane_prediction['height']\n",
    "\n",
    "                    if motorcyclist_x1 < rear_x < motorcyclist_x2 and motorcyclist_y1 < rear_y < motorcyclist_y2:\n",
    "                        rear_detected = True\n",
    "                        break\n",
    "\n",
    "            # Face detected\n",
    "            r2 = client2.infer(\"temp_motorcyclist_image.jpg\", model_id=\"face-detection-mik1i/21\")\n",
    "            pred2 = r2['predictions']\n",
    "\n",
    "            for face_prediction in pred2:\n",
    "                if face_prediction['class'] == 'face':\n",
    "                    face_x, face_y, face_width, face_height = face_prediction['x'], face_prediction['y'], face_prediction['width'], face_prediction['height']\n",
    "\n",
    "                    if motorcyclist_x1 < face_x < motorcyclist_x2 and motorcyclist_y1 < face_y < motorcyclist_y2:\n",
    "                        num_faces_detected += 1\n",
    "\n",
    "                        # Avoid detecting helmet and face in same area and calculating number of people incorrectly\n",
    "                        for helmet_prediction in pred1:\n",
    "                            if helmet_prediction['class'] == 'helmet':\n",
    "                                helmet_x, helmet_y, helmet_width, helmet_height = helmet_prediction['x'], helmet_prediction['y'], helmet_prediction['width'], helmet_prediction['height']\n",
    "                                \n",
    "                                face_x1 = face_x - face_width / 2\n",
    "                                face_y1 = face_y - face_height / 2\n",
    "                                face_x2 = face_x + face_width / 2\n",
    "                                face_y2 = face_y + face_height / 2\n",
    "\n",
    "                                helmet_x1 = helmet_x - helmet_width / 2\n",
    "                                helmet_y1 = helmet_y - helmet_height / 2\n",
    "                                helmet_x2 = helmet_x + helmet_width / 2\n",
    "                                helmet_y2 = helmet_y + helmet_height / 2\n",
    "\n",
    "                                overlap_x1 = max(face_x, helmet_x)\n",
    "                                overlap_y1 = max(face_y, helmet_y)\n",
    "                                overlap_x2 = min(face_x + face_width, helmet_x + helmet_width)\n",
    "                                overlap_y2 = min(face_y + face_height, helmet_y + helmet_height)\n",
    "\n",
    "                                overlap_width = max(0, overlap_x2 - overlap_x1)\n",
    "                                overlap_height = max(0, overlap_y2 - overlap_y1)\n",
    "\n",
    "                                overlap_area = overlap_width * overlap_height\n",
    "\n",
    "                                face_area = face_width * face_height\n",
    "\n",
    "                                if overlap_area / face_area > 0.6:\n",
    "                                    num_faces_detected -= 1\n",
    "                                    break\n",
    "\n",
    "            if num_faces_detected > 0:\n",
    "                face_detected = True\n",
    "\n",
    "            # Helmet check\n",
    "            for helmet_prediction in pred1:\n",
    "                if helmet_prediction['class'] == 'helmet':\n",
    "                    helmet_x, helmet_y, helmet_width, helmet_height = helmet_prediction['x'], helmet_prediction['y'], helmet_prediction['width'], helmet_prediction['height']\n",
    "\n",
    "                    if motorcyclist_x1 < helmet_x < motorcyclist_x2 and motorcyclist_y1 < helmet_y < motorcyclist_y2:\n",
    "                        helmet_detected = True\n",
    "                        num_helmets_detected += 1\n",
    "\n",
    "            # More than two riding\n",
    "            if num_faces_detected + num_helmets_detected > 2:\n",
    "                more_than_two_detected = True\n",
    "\n",
    "            # r4 = m1.predict(\"temp_motorcyclist_image.jpg\", confidence=60, overlap=40)\n",
    "            r4 = client1.infer(\"temp_motorcyclist_image.jpg\", model_id=\"helmet-detection-project/13\")\n",
    "            colored_motorcycle = draw_detections(r4, r2, lane, motorcyclist_image)\n",
    "            \n",
    "            # Violated license plate\n",
    "            if not helmet_detected or face_detected or rear_detected or more_than_two_detected:\n",
    "                \n",
    "                violation_names = []\n",
    "                if not helmet_detected or face_detected:\n",
    "                    violation_names.append('no_helmet')\n",
    "                if rear_detected:\n",
    "                    violation_names.append('wrong_lane')\n",
    "                if more_than_two_detected:\n",
    "                    violation_names.append('triple_riding')\n",
    "\n",
    "                timestamp = datetime.now(timezone.utc).astimezone(timezone(timedelta(hours=5, minutes=30))).strftime(\"%d-%m-%Y %H %M %S\")\n",
    "                image_name = \", \".join(violation_names) + f\" - {timestamp}\"\n",
    "                lp_detected = False\n",
    "\n",
    "                for pr11 in pred1:\n",
    "                    if pr11['class'] == 'license_plate':\n",
    "                        license_plate_x, license_plate_y, license_plate_width, license_plate_height = pr11['x'], pr11['y'], pr11['width'], pr11['height']\n",
    "                        if motorcyclist_x1 < license_plate_x < motorcyclist_x2 and motorcyclist_y1 < license_plate_y < motorcyclist_y2:\n",
    "                            license_plate_x1, license_plate_y1 = int(license_plate_x - license_plate_width / 2), int(license_plate_y - license_plate_height / 2)\n",
    "                            license_plate_x2, license_plate_y2 = int(license_plate_x + license_plate_width / 2), int(license_plate_y + license_plate_height / 2)\n",
    "            \n",
    "                            license_plate_image = pil_frame.crop((license_plate_x1, license_plate_y1, license_plate_x2, license_plate_y2))\n",
    "                            \n",
    "                            license_plate_image.save(\"temp_lp.jpg\")\n",
    "                            lpnum = ocr_space_file(filename=\"temp_lp.jpg\", overlay=False, api_key=config(\"OCR_SPACE_API\"), language='eng')   \n",
    "\n",
    "                            if lpnum.strip():\n",
    "                                image_name = lpnum + \" - \" + image_name\n",
    "                            else:\n",
    "                                image_name = image_name\n",
    "                            image_folder_path = os.path.join(folder_path, image_name)\n",
    "                            os.makedirs(image_folder_path, exist_ok=True)\n",
    "\n",
    "                            violated_motorcycle_image_path = os.path.join(image_folder_path, f\"{lpnum} - motorcyclist.jpg\")\n",
    "                            colored_motorcycle.save(violated_motorcycle_image_path)\n",
    "\n",
    "                            violated_motorcycle_lp_image_path = os.path.join(image_folder_path, f\"{lpnum} - license_plate.jpg\")\n",
    "                            license_plate_image.save(violated_motorcycle_lp_image_path)\n",
    "\n",
    "                            lp_text_path = os.path.join(image_folder_path, f\"{lpnum} - license_plate_number.txt\")\n",
    "                            with open(lp_text_path, 'w') as file:\n",
    "                                file.write(f\"Violated License Plate Number - {lpnum}\")\n",
    "\n",
    "                            lp_detected = True\n",
    "\n",
    "                            if os.path.exists(\"temp_lp.jpg\"):\n",
    "                                os.remove(\"temp_lp.jpg\")\n",
    "                            break\n",
    "\n",
    "                if not lp_detected:\n",
    "                    image_folder_path = os.path.join(folder_path, image_name)\n",
    "                    os.makedirs(image_folder_path, exist_ok=True)\n",
    "                    violated_motorcycle_image_path = os.path.join(image_folder_path, f\"motorcyclist.jpg\")\n",
    "\n",
    "                    colored_motorcycle.save(violated_motorcycle_image_path)\n",
    "\n",
    "\n",
    "if os.path.exists(\"temp_motorcyclist_image.jpg\"):\n",
    "    os.remove(\"temp_motorcyclist_image.jpg\")\n",
    "cap.release()\n",
    "\n",
    "print(\"Video processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
